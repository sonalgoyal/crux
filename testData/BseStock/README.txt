Instructions to download and populate stock data.

1. Fetch stock BSE data from the BSE website for a particular date range by executing downloadBseData.py. Arguments required are 
a. complete filePath which has the list of stockIds. Data for these stocks will be downloaded. 
b. startDate in MM/dd/yyyy format
c. endDate in MM/dd/yyyy format
d. outputPath where these files will be saved after downloaded.

For example:
./downloadBseData.py ./stockIdsList.txt 01/06/2011 05/06/2011 /outputPath

The above command will fetch files for all stockIds listed in stockIdsList.txt. 
The files will be copied to outputPath defined by user. Each stock's data will be saved with the name of the stockIds. 

2. We now need to change the data so that our row key is a composite of stock id and the date. 
Run createTableData.py to concatenate stockId with date(yyyyMMdd), which can be used later as the rowkey while loading.
Arguments required for this script are inputPath where the downloaded bse data is kept and outputPath
For example: 
./createTableData.py downloadPath outputPath

downloadPath - path to directory where all file exists from step 1.
outputPath - path where concatenated data will be placed.

3. We now want to save this data in HBase. Let us create a table in HBase stockData with column families price, spread and stats

On the hbase shell, this can be done as follows:
create 'stockData','price','spread','stats'

4. Now that the data is downloaded and prepared, we are ready to import it into HBase.

a. Include HBASE_HOME/lib/ to HADDOP_CLASSPATH.

6. Load data in hbase:-

To put data as rowKey string :- 

a. Run importtsv command through hadoop to prepare data for bulk load in HBase
HADOOP_HOME/bin/hadoop jar HBASE_HOME/hbase-0.90.3.jar importtsv -Dimporttsv.columns=HBASE_ROW_KEY,price:open,price:high,price:low,price:close,stats:wap,stats:numShares,stats:numTrades,stats:turnOver,spread:highLow,spread:closeOpen -Dimporttsv.separator=","  -Dimporttsv.bulk.output=outputHBase stockData /user/nube/hbaseData/

-Dimporttsv.columns is format of table.
-Dimporttsv.separator is to define separator in dataFile
-Dimporttsv.bulk.output is to define outputPath for this job
stockData is tablename for which we are preparing data
/user/nube/hbaseData/ this define inputPath (is the path to the directory where files generated by createTableData.py is kept).

b.Run completebulkload command through hadoop to load data in HBase
HADOOP_HOME/bin/hadoop jar HBASE_HOME/hbase-0.90.3.jar completebulkload /user/nube/outputHBase stockData

/user/nube/outputHBase this define inputPath(is output of above step).
stockData is tablename where we wanna insert data.
Note: In this method all data is inserted as String type.

OR

To put data as composite rowKey long stockId ,String date both concatenated :- 
a.Create table in HBase. On the shell,

create 'stockData1','price','spread','stats'

b.Execute java program PopulateBseData.java, just need one argument inputpath i.e. outputPath of step 2 in this README.
Note:in this step all data inserted in table stockData1 as Float type except rowkey as composite key, numShares and numTrades as long type.
java PopulateBseData /inputPath 

inputPath: is the path to the directory where files generated by createTableData.py is kept.